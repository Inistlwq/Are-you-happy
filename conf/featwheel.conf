[DIRECTORY]
project_pt = ../../Are-you-happy-FileSystem/
data_pt = %(project_pt)s/data/
devel_pt = %(data_pt)s/devel/
source_pt = %(data_pt)s/source/
origin_pt = %(data_pt)s/origin/
feature_pt = %(data_pt)s/feature/
index_pt = %(data_pt)s/index/
label_pt = %(data_pt)s/label/
feature_analysis_pt = %(data_pt)s/feature_analysis/
origin_spanish_pt = %(data_pt)s/origin_spanish/
csv_spanish_pt = %(data_pt)s/csv_spanish/
csv_spanish_cleaning_pt = %(data_pt)s/csv_spanish_cleaning/
model_tag = 2018-07-07_08-25-51/
out_pt = %(data_pt)s/out/%(out_tag)s/
pred_pt = %(out_pt)s/pred/
index_out_pt = %(out_pt)s/index/
model_pt = %(out_pt)s/model/
fault_pt = %(out_pt)s/fault_pt/
conf_pt = %(out_pt)s/conf/
score_pt = %(out_pt)s/score/

[FILE_NAME]
cikm_english_train_20180516_txt = cikm_english_train_20180516.txt
cikm_spanish_train_20180516_txt = cikm_spanish_train_20180516.txt
cikm_unlabel_spanish_train_20180516_txt = cikm_unlabel_spanish_train_20180516.txt
cikm_test_a_20180516_txt = cikm_test_a_20180516.txt
cikm_english_train_20180516_csv = cikm_english_train_20180516.csv
cikm_spanish_train_20180516_csv = cikm_spanish_train_20180516.csv
cikm_unlabel_spanish_train_20180516_csv = cikm_unlabel_spanish_train_20180516.csv
cikm_test_a_20180516_csv = cikm_test_a_20180516.csv
cikm_english_and_spanish_train_20180516_csv = cikm_english_and_spanish_train_20180516.csv
powerful_word_name = words_power
preprocessing_train_merge_csv = preprocessing_train_merge.csv
preprocessing_test_csv = preprocessing_test.csv
words_txt = words.txt
wiki_es_vec = wiki.es.vec

[SINGLE_EXEC]
se_num = 100
se_train_rate = 0.9
se_cv_rate = 0.09
se_test_rate = 0.01
se_seed = 10
se_tag = 

[CROSS_VALIDATION]
cv_num = 5
cv_tag = 


[MODEL]
model_name = GradientBoost
train_pos_rate = 0.25
valid_pos_rate = 0.25
test_pos_rate = 0.25
offline_rawset_name = train
online_rawset_name = test
lock_name = lock_name
lock_time = 1
lock_pt = C:/Users/jieyang/Desktop/GIT_code/kaggle-quora-question-pairs/
evaluator_name = entropy_loss


[XGB_PARAMS]
booster = gbtree 
objective = binary:logistic
eval_metric = logloss
eta = 0.05
max_depth = 6
subsample = 0.7
colsample_bytree = 1
min_child_weight = 50
silent = 1
num_round = 2000
early_stop = 10000
nthread = 6
scale_pos_weight = 0.25
verbose_eval = 10
gamma = 1
lambda = 3
alpha = 2


[LOGISTIC_REGRESSION_PARAMS]
penalty = l2
dual = False
tol = 1e-4
C = 1.
verbose = 0
max_iter = 100
solver = liblinear
n_jobs = 1
multi_class = ovr

[RANDOMFOREST]
n_estimators = 1000
max_features = 10
max_depth = 10
min_samples_split = 10
n_jobs = 4
random_state =0
loss = deviance

[GBDT]
n_estimators = 100
loss = deviance
max_depth = 6
verbose = 1

[FEATURE]
begin_index = 0
end_index = 21400
will_save = False
offline_rawset_name = preprocessing_train_merge.csv
online_rawset_name = preprocessing_test.csv
feature_selected =
    WordMatchShare
	TFIDFWordMatchShare
	Length
	LengthDiff
	LengthDiffRate
	DulNum
	EnCharCount
	NgramJaccardCoef
	NgramDiceDistance
	NgramDistance_edit_dist
	Not
	TFIDF
	PowerfulWordDoubleSideRate
	NMFDecomposition
	LDADecomposition
	PhraseToSentenceDistance_edit_dist
    sentence_representation_distance
    sentence_representation_tfidf_distance
    fuzz_QRatio
    fuzz_WRatio
    fuzz_partial_ratio
    fuzz_partial_token_set_ratio
    fuzz_partial_token_sort_ratio
    fuzz_token_set_ratio
    fuzz_token_sort_ratio
    long_common_sequence
    long_common_prefix
    long_common_suffix
    long_common_substring
    levenshtein_distance
feature_selected_analysis = 
    TFIDF 
feature_selected_num_analysis =
	TFIDF-6-
	